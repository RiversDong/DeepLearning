自注意力机制中是让最后生成的Z具有更多的信息去表示初始的词向量，是不是还有更加完善的方法去让Z表示更多更多的信息呢？ 现在有了就是multi-head 自注意力机制。

#### 多头自注意力机制（multi-head self-attention）
Z相比于X有了提升，通过多头自注意力机制得到的Z' 相比于Z有拥有了进一步的提升。    
那么多头是什么意思呢？请看下面的图片，多头一般用h表示，h默认情况下等于8，我们通常使用的是8投自注意力机制    

![image](https://github.com/RiversDong/DeepLearning/assets/45725241/125934a2-3af5-47a8-9d8a-2f7f8bbd796f)

多头自注意力机制如何进行计算呢？请看下面的图片     
对于X，我们不是直接拿X去得到Z，而是把X分成了8块（8头），得到Z0-Z7
![image](https://github.com/RiversDong/DeepLearning/assets/45725241/49900607-9688-4b42-a9b4-b2971663db6d)    


得到Z0到Z7以后把Z0到Z7拼接起来，再做一次线性变换（改变维度）得到Z
![image](https://github.com/RiversDong/DeepLearning/assets/45725241/8d5f949c-39b5-4306-b1f2-29f0c56e7f44)    
![image](https://github.com/RiversDong/DeepLearning/assets/45725241/2ce2222b-67a9-4b86-aced-3ba90cb31f07)    


多头自注意力机制有什么作用？来看下面的图    
```
机器学习的本质是将wx+b进行现象或者非线性变换，把一个不合理的东西看起来合理，通过某个手段让某个东西变得合理（训练模型） 
非线性变换的本事是什么? 改变空间上的位置坐标，任何一个点都可以再维度空间上找到。通过某种手段，让一个不合理的点（位置不合理）变得合理 这就是词向量的本质。

多头自注意力机制中将原先位于一个位置上的X通过多头自注意力机制分成了8个部分，相当于X分散到了空间的8个位置，通过对8个点进行寻找找到更合适的位置
```

#### 多头自注意力机制的流程


![image](https://github.com/RiversDong/DeepLearning/assets/45725241/7d012464-cbda-4fb9-a2d3-b18d0662012d)








