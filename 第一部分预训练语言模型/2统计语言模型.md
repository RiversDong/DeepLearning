## 统计语言模型
### 语言模型

语言 + 模型分为两个任务：分类任务和回归任务。例如：P(A)和P(B)的大小（任务1）；判断这个词的_____(任务二)。

### 统计语言模型
用统计的方法解决上述两个语言模型的任务，一种解决办法是条件概率（条件概率的链式法则），通过这个公式可以计算每一个词在前面词出现的基础上算出下一个词出现的概率，所有的概率相乘就可以算出这句话出现的概率
![image](https://github.com/RiversDong/DeepLearning/assets/45725241/3fa17093-5c44-409b-8e59-57c3d8dd7b97)。
那我们如何解决第二个任务呢？即最大化这个概率即可P(__|"判断这个词的")，如何去算呢？假设我们由一个词库V，所有词都会在词库V中出现，可以基于V，可以使用条件概率的链式法则进行所有词的计算，可以得到当出现“判断这个词的”以后下一个词的概率
，进而可以得到哪一个词出现在“判断这个词的”后面的概率，概率最大的词应该写在下划线处。   

然而这样计算要花费太多的时间，因此词库里面的词汇量太大太大了。所以需要其它的手段来解决这个问题，下面来看看如何进一步简化上述的计算。

### n元统计语言模型
P(词性|"这个"，“词”， “的”)  
P(词性|“词”， “的”)  
P(词性|“的”)
既可以把n个词取出起哄的几个词，例如2个词（2元）或者3个词（2元），也可以近似的代替这n个词，这样就缩减了词汇的数量

### 平滑策略
假设要计算的词在前面词出现的基础上出现的概率，然而这个词恰好没有在词汇表里面出现，这个时候计算概率的时候，分子或者分母会出现0的情况，这显然是是合理的，所以平滑策略就是针对条件概率进行的改版

### 总结
语言模型是去计算一句话出现的概率或者去计算一句话出现的时候下一个词出现的概率   
统计语言模型是用统计的方法去解决语言模型的任务（条件概率）    
然而条件概率词汇的数量很多，因此用n元统计语言模型去解决条件概率计算量大的问题，其实是选择性的缩减词汇量   
条件概率应用的时候为了避免分母或者分子为0时，使用平滑策略解决，避免出现0/0的计算
