#### Word2vec
是一个神经网络语言模型，其次他的主要任务是生成词向量。就是生成Q矩阵。现在假设我们生成好了Q矩阵（如下图）。我现在给你抛出一个问题：word2vec模型是不是预训练模型？我的答案肯定是预训练 
       
![image](https://github.com/RiversDong/DeepLearning/assets/45725241/645df933-584b-4b42-8a9e-417a65f70596)

### 解释word2vec模型是预训练模型
要解释这个问题首先要知道什么是预训练：给出连个任务A和B，任务A已经做出了模型A，但是任务B数据量比较小。通过使用模型A来加快运算，得以解决任务B。

比如问答问题，给你一个X，你给个回答Y，回答Y是问题X解决。再比如下图

![image](https://github.com/RiversDong/DeepLearning/assets/45725241/4dd083c4-2239-4170-9ce7-ca57bf8d16a7)

预训练语言模型终于要出来了（给出一句话，我们先使用独热编码，再使用Word2Vec预训练好的Q矩阵直接得到词向量，然偶进行接下来的任务）   
* 冻结
* 微调
